{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(X,y,learning_rate,no_of_iteration,m):\n",
    "    \n",
    "    M = X.shape[0] #row\n",
    "    N = X.shape[1] #col\n",
    "    \n",
    "    m_slope = np.zeros(N)\n",
    "    for i in range(M):\n",
    "        x = X[i]\n",
    "        y_pred = (m*x).sum()\n",
    "        for j in range(N):\n",
    "            m_slope[j]+= (-2/M)*(y[i]-y_pred)*x[j]\n",
    "    m = m-learning_rate*m_slope\n",
    "    #print(m)\n",
    "    return m\n",
    "    \n",
    "def cost(X, Y, m):\n",
    "    return ((Y - np.sum(m*X, axis = 1))**2).mean()\n",
    "    \n",
    "\n",
    "def gradient_descent(x_train,y_train,learning_rate,no_of_iteration):\n",
    "    m  = np.zeros(x_train.shape[1])\n",
    "    for i in range(no_of_iteration):\n",
    "        m = step_gradient(x_train,y_train,learning_rate,no_of_iteration,m)\n",
    "        print(i+1, \" Cost: \", cost(x_train,y_train, m))  \n",
    "    return m\n",
    "    \n",
    "\n",
    "def predict(X, m):\n",
    "    return np.sum(m*X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.91816626 -0.48772236  1.01599907 ...  0.80657583 -1.59755122\n",
      "   1.04106182]\n",
      " [-0.40339151 -0.48772236  0.40609801 ... -1.13534664  0.44105193\n",
      "  -0.89473812]\n",
      " [-0.4131781  -0.48772236  0.11573841 ...  1.17646583  0.44105193\n",
      "  -0.50084979]\n",
      " ...\n",
      " [-0.41001449  2.08745172 -1.37837329 ... -0.0719129   0.39094481\n",
      "  -0.68167397]\n",
      " [-0.40317611 -0.48772236 -0.37597609 ...  1.13022958  0.34007019\n",
      "   0.20142086]\n",
      " [-0.13356344 -0.48772236  1.2319449  ... -1.73641788 -2.93893082\n",
      "   0.48877712]]\n",
      "X_test\n",
      "[[ 2.91816626 -0.48772236  1.01599907 ... -1.59755122  1.04106182\n",
      "   1.        ]\n",
      " [-0.40339151 -0.48772236  0.40609801 ...  0.44105193 -0.89473812\n",
      "   1.        ]\n",
      " [-0.4131781  -0.48772236  0.11573841 ...  0.44105193 -0.50084979\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.41001449  2.08745172 -1.37837329 ...  0.39094481 -0.68167397\n",
      "   1.        ]\n",
      " [-0.40317611 -0.48772236 -0.37597609 ...  0.34007019  0.20142086\n",
      "   1.        ]\n",
      " [-0.13356344 -0.48772236  1.2319449  ... -2.93893082  0.48877712\n",
      "   1.        ]]\n",
      "1  Cost:  598.8391251684227\n",
      "2  Cost:  598.5562142974782\n",
      "3  Cost:  598.2735361338925\n",
      "4  Cost:  597.9910902959725\n",
      "5  Cost:  597.7088764028895\n",
      "6  Cost:  597.4268940746783\n",
      "7  Cost:  597.1451429322346\n",
      "8  Cost:  596.8636225973136\n",
      "9  Cost:  596.5823326925263\n",
      "10  Cost:  596.3012728413395\n",
      "[[-0.06775778]\n",
      " [ 0.0973688 ]\n",
      " [ 0.04303577]\n",
      " [ 0.09633722]\n",
      " [ 0.04241643]\n",
      " [-0.05566462]\n",
      " [ 0.09209837]\n",
      " [ 0.06851518]\n",
      " [ 0.03777489]\n",
      " [ 0.06292634]\n",
      " [ 0.07905023]\n",
      " [ 0.03486656]\n",
      " [ 0.07433547]\n",
      " [ 0.05669867]\n",
      " [ 0.11966159]\n",
      " [ 0.09740879]\n",
      " [ 0.07971902]\n",
      " [ 0.07871997]\n",
      " [ 0.08338729]\n",
      " [ 0.09418969]\n",
      " [ 0.04707654]\n",
      " [ 0.03171394]\n",
      " [ 0.06748906]\n",
      " [ 0.13169441]\n",
      " [ 0.14785105]\n",
      " [-0.03135551]\n",
      " [ 0.0463372 ]\n",
      " [ 0.11611055]\n",
      " [ 0.0547849 ]\n",
      " [ 0.09458672]\n",
      " [ 0.0353029 ]\n",
      " [ 0.07494754]\n",
      " [ 0.05279253]\n",
      " [ 0.07838793]\n",
      " [-0.03883278]\n",
      " [ 0.07454791]\n",
      " [ 0.09343141]\n",
      " [ 0.03463043]\n",
      " [ 0.08951377]\n",
      " [-0.06613134]\n",
      " [-0.08286765]\n",
      " [ 0.10366726]\n",
      " [ 0.13155736]\n",
      " [ 0.01617912]\n",
      " [-0.00141287]\n",
      " [-0.09671483]\n",
      " [ 0.12132936]\n",
      " [ 0.06330523]\n",
      " [ 0.15238354]\n",
      " [-0.02335675]\n",
      " [-0.0274466 ]\n",
      " [ 0.16864929]\n",
      " [-0.02132599]\n",
      " [ 0.03477899]\n",
      " [ 0.02960523]\n",
      " [ 0.06322444]\n",
      " [ 0.03894351]\n",
      " [ 0.06418947]\n",
      " [ 0.01868366]\n",
      " [-0.02256782]\n",
      " [-0.05525146]\n",
      " [ 0.07369453]\n",
      " [ 0.0711252 ]\n",
      " [ 0.07776597]\n",
      " [-0.02816613]\n",
      " [-0.03642347]\n",
      " [ 0.10078402]\n",
      " [-0.02448157]\n",
      " [ 0.06847665]\n",
      " [ 0.01667892]\n",
      " [ 0.08906042]\n",
      " [ 0.03874354]\n",
      " [-0.00048414]\n",
      " [-0.08461068]\n",
      " [ 0.15786729]\n",
      " [ 0.08225267]\n",
      " [ 0.10094415]\n",
      " [ 0.09165151]\n",
      " [-0.03491609]\n",
      " [ 0.14968917]\n",
      " [-0.01011729]\n",
      " [ 0.04140797]\n",
      " [ 0.07431825]\n",
      " [ 0.01728713]\n",
      " [-0.01942879]\n",
      " [ 0.1120389 ]\n",
      " [ 0.10298891]\n",
      " [-0.07804009]\n",
      " [ 0.02296702]\n",
      " [-0.0152048 ]\n",
      " [ 0.06775889]\n",
      " [ 0.0326639 ]\n",
      " [ 0.0318422 ]\n",
      " [-0.04434437]\n",
      " [ 0.04919877]\n",
      " [ 0.03796991]\n",
      " [ 0.17029091]\n",
      " [ 0.01356541]\n",
      " [ 0.13864564]\n",
      " [ 0.11041503]\n",
      " [ 0.06911485]\n",
      " [ 0.06935021]\n",
      " [ 0.08167741]\n",
      " [ 0.0935545 ]\n",
      " [-0.03092099]\n",
      " [ 0.07529898]\n",
      " [ 0.07763792]\n",
      " [ 0.16451274]\n",
      " [ 0.08832046]\n",
      " [-0.03746763]\n",
      " [ 0.12542557]\n",
      " [-0.10739738]\n",
      " [ 0.00899037]\n",
      " [-0.04009605]\n",
      " [ 0.12105348]\n",
      " [ 0.02591536]\n",
      " [ 0.05243501]\n",
      " [ 0.07158243]\n",
      " [ 0.08078121]\n",
      " [ 0.00308463]\n",
      " [ 0.01890788]\n",
      " [ 0.12156092]\n",
      " [ 0.05799266]\n",
      " [ 0.07345673]\n",
      " [ 0.10721171]\n",
      " [ 0.03200841]\n",
      " [-0.01960927]]\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "    data            = np.genfromtxt(\"trainCC.csv\",delimiter=\",\")\n",
    "    testing         = np.genfromtxt(\"testCC.csv\",delimiter=\",\")\n",
    "    no_of_iteration = 10\n",
    "    learning_rate   = 0.0001 \n",
    "    x_train,y_train = data[:,:-1],data[:,-1]\n",
    "    #print(x_train)\n",
    "    print(testing)\n",
    "    #np.savetxt(\"x_train.csv\",x_train)\n",
    "    #print(yesting.shape)\n",
    "    x_train = np.insert(x_train, x_train.shape[1], 1, axis = 1)  # this is for c , \"1\" column \n",
    "    #print(\"X_train--\")\n",
    "    #print(x_train)\n",
    "    x_test  = np.insert(testing, testing.shape[1], 1, axis = 1)\n",
    "    print(\"X_test\")\n",
    "    print(x_test)\n",
    "    \n",
    "    m = gradient_descent(x_train,y_train,learning_rate,no_of_iteration)\n",
    "    #print(x_test.shape,m.shape)\n",
    "    y_pred = predict(x_test,m)\n",
    "    y_pred = y_pred.reshape(x_test.shape[0],1)\n",
    "    print(y_pred)\n",
    "    np.savetxt(\"output.csv\",y_pred,fmt=\"%.5f\")\n",
    "    \n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
