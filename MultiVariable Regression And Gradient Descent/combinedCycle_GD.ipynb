{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"0000000000002419_training_ccpp_x_y_train.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7176, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0:4]\n",
    "Y = data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7176, 4), (7176,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.append(X_scaled,np.ones(X_scaled.shape[0]).reshape(-1,1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7176, 5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X_train,m,Y_train):\n",
    "    cost_ = 0\n",
    "    N = X_train.shape[0]\n",
    "    for i in range(N):\n",
    "        cost_ += (1/N)*((Y_train[i]-((X_train[i]*m).sum()))**2)\n",
    "    return cost_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(X_train,Y_train,m,lr):\n",
    "    \n",
    "    slope_m = np.zeros(X_train.shape[1])\n",
    "    N = X_train.shape[0]\n",
    "    \n",
    "    for i in range(N):\n",
    "        slope_m += (2/N)*(Y_train[i]-(m*X_train[i]).sum())*(-X_train[i])\n",
    "        \n",
    "    m = m - (lr * slope_m)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train,Y_train,lr=0.001,epochs=100,verbose=False):\n",
    "    m = np.zeros(X_train.shape[1])\n",
    "    last_m = m\n",
    "    cost_array = []\n",
    "    unit = epochs//100\n",
    "    for i in range(epochs+1):\n",
    "        last_m = m\n",
    "        m = step_gradient(X_train,Y_train,m,lr)\n",
    "        cost_ = cost(X_train,m,Y_train)\n",
    "        \n",
    "        #verbose is used to only show the learning process if required, else it is False by default\n",
    "        if verbose and i%unit==0:\n",
    "            print(\"epoch:\",i,\"cost:\",cost_)\n",
    "            cost_array.append(cost_)\n",
    "    \n",
    "    #To continue the learning loop incase the current epoch and learning parameters doesn't lead to saturation\n",
    "    cont = input(\"Do you want to continue?:\")\n",
    "        \n",
    "    while cont==\"y\":\n",
    "        clear_output(wait=True)\n",
    "        epochs = int(input(\"Please enter the number of epochs to continue for:\"))\n",
    "        unit = int(input(\"Please enter the unit point for epochs:\"))\n",
    "        lr_factor = float(input(\"Please enter the decay factor for the learning rate:\"))\n",
    "        lr*=lr_factor\n",
    "        for i in range(epochs+1):\n",
    "            last_m = m\n",
    "            m = step_gradient(X_train,Y_train,m,lr)\n",
    "            cost_ = cost(X_train,m,Y_train)\n",
    "            if verbose and i%unit==0:\n",
    "                print(\"epoch:\",i,\"cost:\",cost_)\n",
    "                cost_array.append(cost_)\n",
    "        cont = input(\"Do you want to continue?:\")\n",
    "        \n",
    "    return m,cost_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test,m):\n",
    "    y_pred = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        y_pred.append((X_test[i]*m).sum())\n",
    "    return np.array(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(Y_true,Y_pred):\n",
    "    u = ((Y_true-Y_pred)**2).sum()\n",
    "    v = ((Y_true-(Y_true.mean()))**2).sum()\n",
    "    return 1-(u/v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 cost: 132273.17028197853\n",
      "epoch: 10 cost: 1552.762193756394\n",
      "epoch: 20 cost: 43.193704743608556\n",
      "epoch: 30 cost: 24.176010622787736\n",
      "epoch: 40 cost: 22.937255128393236\n",
      "epoch: 50 cost: 22.252171183169498\n",
      "epoch: 60 cost: 21.800137519716298\n",
      "epoch: 70 cost: 21.50059001236028\n",
      "epoch: 80 cost: 21.302047696213297\n",
      "epoch: 90 cost: 21.170449172278783\n",
      "epoch: 100 cost: 21.08322226502254\n",
      "epoch: 110 cost: 21.025405983415762\n",
      "epoch: 120 cost: 20.98708383277924\n",
      "epoch: 130 cost: 20.961682904083958\n",
      "epoch: 140 cost: 20.944846500881333\n",
      "epoch: 150 cost: 20.93368689029104\n",
      "epoch: 160 cost: 20.926290007059148\n",
      "epoch: 170 cost: 20.921387158424483\n",
      "epoch: 180 cost: 20.91813742147707\n",
      "epoch: 190 cost: 20.915983410408472\n",
      "epoch: 200 cost: 20.914555675253386\n",
      "epoch: 210 cost: 20.9136093348644\n",
      "epoch: 220 cost: 20.91298207557985\n",
      "epoch: 230 cost: 20.912566311638262\n",
      "epoch: 240 cost: 20.9122907323695\n",
      "epoch: 250 cost: 20.912108071186392\n",
      "epoch: 260 cost: 20.911986998553033\n",
      "epoch: 270 cost: 20.91190674842922\n",
      "epoch: 280 cost: 20.911853556537633\n",
      "epoch: 290 cost: 20.911818299553975\n",
      "epoch: 300 cost: 20.911794930298345\n",
      "epoch: 310 cost: 20.911779440541455\n",
      "epoch: 320 cost: 20.911769173523428\n",
      "epoch: 330 cost: 20.911762368273894\n",
      "epoch: 340 cost: 20.911757857575886\n",
      "epoch: 350 cost: 20.911754867766607\n",
      "epoch: 360 cost: 20.9117528860423\n",
      "epoch: 370 cost: 20.91175157250336\n",
      "epoch: 380 cost: 20.911750701855315\n",
      "epoch: 390 cost: 20.91175012476689\n",
      "epoch: 400 cost: 20.911749742257367\n",
      "epoch: 410 cost: 20.911749488720112\n",
      "epoch: 420 cost: 20.91174932066889\n",
      "epoch: 430 cost: 20.91174920928015\n",
      "epoch: 440 cost: 20.911749135448865\n",
      "epoch: 450 cost: 20.91174908651154\n",
      "epoch: 460 cost: 20.911749054074555\n",
      "epoch: 470 cost: 20.911749032574374\n",
      "epoch: 480 cost: 20.91174901832356\n",
      "epoch: 490 cost: 20.91174900887778\n",
      "epoch: 500 cost: 20.911749002616755\n",
      "epoch: 510 cost: 20.91174899846686\n",
      "epoch: 520 cost: 20.911748995716156\n",
      "epoch: 530 cost: 20.911748993892996\n",
      "epoch: 540 cost: 20.911748992684494\n",
      "epoch: 550 cost: 20.9117489918836\n",
      "epoch: 560 cost: 20.911748991352592\n",
      "epoch: 570 cost: 20.911748991000692\n",
      "epoch: 580 cost: 20.91174899076745\n",
      "epoch: 590 cost: 20.911748990612747\n",
      "epoch: 600 cost: 20.911748990510375\n",
      "epoch: 610 cost: 20.911748990442398\n",
      "epoch: 620 cost: 20.911748990397395\n",
      "epoch: 630 cost: 20.911748990367556\n",
      "epoch: 640 cost: 20.91174899034783\n",
      "epoch: 650 cost: 20.91174899033452\n",
      "epoch: 660 cost: 20.911748990325936\n",
      "epoch: 670 cost: 20.911748990320167\n",
      "epoch: 680 cost: 20.9117489903165\n",
      "epoch: 690 cost: 20.911748990313793\n",
      "epoch: 700 cost: 20.911748990312184\n",
      "epoch: 710 cost: 20.911748990311033\n",
      "epoch: 720 cost: 20.911748990310297\n",
      "epoch: 730 cost: 20.911748990309817\n",
      "epoch: 740 cost: 20.911748990309626\n",
      "epoch: 750 cost: 20.911748990309444\n",
      "epoch: 760 cost: 20.911748990309153\n",
      "epoch: 770 cost: 20.91174899030913\n",
      "epoch: 780 cost: 20.911748990309007\n",
      "epoch: 790 cost: 20.911748990308965\n",
      "epoch: 800 cost: 20.911748990308965\n",
      "epoch: 810 cost: 20.91174899030894\n",
      "epoch: 820 cost: 20.91174899030896\n",
      "epoch: 830 cost: 20.91174899030892\n",
      "epoch: 840 cost: 20.911748990308787\n",
      "epoch: 850 cost: 20.911748990308897\n",
      "epoch: 860 cost: 20.91174899030891\n",
      "epoch: 870 cost: 20.91174899030881\n",
      "epoch: 880 cost: 20.911748990308965\n",
      "epoch: 890 cost: 20.911748990308936\n",
      "epoch: 900 cost: 20.911748990308933\n",
      "epoch: 910 cost: 20.911748990308933\n",
      "epoch: 920 cost: 20.911748990308848\n",
      "epoch: 930 cost: 20.91174899030889\n",
      "epoch: 940 cost: 20.911748990308947\n",
      "epoch: 950 cost: 20.91174899030891\n",
      "epoch: 960 cost: 20.911748990308958\n",
      "epoch: 970 cost: 20.911748990308823\n",
      "epoch: 980 cost: 20.911748990308904\n",
      "epoch: 990 cost: 20.91174899030881\n",
      "epoch: 1000 cost: 20.911748990308887\n",
      "[-1.49027293e+01 -2.89427819e+00  3.49739963e-01 -2.34230171e+00\n",
      "  4.54431293e+02]\n"
     ]
    }
   ],
   "source": [
    "m, cost_array = fit(X_,Y,epochs=1000,lr=0.1,verbose=True)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7176,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(X_,m)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9287632000440599"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(Y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.loadtxt(\"0000000000002419_test_ccpp_x_test.csv\",delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled_ = np.append(X_test_scaled,np.ones(X_test_scaled.shape[0]).reshape(-1,1),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = predict(X_test_scaled_,m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('pred_feature_scaling.csv',y_pred_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
